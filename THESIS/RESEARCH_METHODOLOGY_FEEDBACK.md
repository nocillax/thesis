# Research Methodology Feedback - Certificate Verification System Thesis

**Date:** December 7, 2025  
**Based on:** Actual implementation review of control (centralized) and proposed (blockchain) systems

---

## 3.1 Introduction & Methodological Approach

**Feasibility:** ‚úÖ Yes

**Recommendations:**

- ‚úÖ Comparative approach is valid - both systems expose REST APIs (control: `/api/certificates`, blockchain: `/api/blockchain`)
- ‚úÖ Add baseline performance test BEFORE attacks to establish normal operation metrics
- ‚ö†Ô∏è Note: Control system has fewer endpoints currently (10 vs 20 in blockchain) - you're building missing ones
- Add a "System Equivalence Verification" phase: confirm both systems return same structure for identical operations

**Needed Info:**

- JWT token generation for both systems (both use `@UseGuards(AuthGuard('jwt'))`)
- Admin credentials for authorized operations
- Baseline dataset: 100-500 certificates issued on both systems before testing
- Network monitoring tools: `netstat`, `tcpdump`, or Wireshark for traffic analysis

**Metrics to Collect (Baseline):**

- Average response time for certificate issuance (10 samples)
- Average response time for certificate verification (100 samples)
- System resource utilization at rest (CPU%, RAM%, Disk I/O)
- Database query time (PostgreSQL) vs RPC call time (Quorum validator1:8545)

---

## 3.2 Research Design

**Feasibility:** ‚úÖ Yes with additions

**Recommendations:**

- ‚úÖ Forgery, tampering, node failure are sufficient core threats
- ‚ö†Ô∏è ADD: **Replay attack test** - JWT token reuse after logout (easy to implement, relevant to both)
- ‚ö†Ô∏è ADD: **Input validation test** - Malformed data (empty strings, negative CGPA, SQL injection attempts)
- ‚ùå SKIP DDoS for now: Requires load balancer setup you don't have; mention as "Future Work"
- ‚úÖ Current threats test different dimensions: data integrity (forgery/tampering) vs availability (node failure)

**Needed Info:**

- Threat prioritization: Which attacks are most realistic for academic certificate systems?
- Attack success criteria: Define what "detection" means (404 response? Error log entry? Transaction revert?)

**Metrics to Collect:**

- Detection rate: % of attacks correctly rejected
- False positive rate: % of legitimate requests incorrectly rejected (if any)
- Mean time to detect (MTTD): How long until system rejects invalid request

---

## 3.3 System Implementation Specs

**Feasibility:** ‚úÖ Yes - accurately reflects your implementation

**Recommendations:**

- ‚úÖ 4 Quorum validators + 1 RPC node IS sufficient for Byzantine fault tolerance (BFT threshold: f=1, need 2f+1=3)
- ‚úÖ Storing audit logs in same PostgreSQL DB is a VALID vulnerability (single point of compromise)
- ‚ö†Ô∏è Clarify: Blockchain audit is event-driven (CertificateIssued, CertificateRevoked events) - NOT stored in DB
- Add: Document that blockchain uses IBFT 2.0 consensus (block time ~5s, immediate finality)

**Needed Info:**

- PostgreSQL version and configuration (default settings or tuned?)
- Quorum network config file location: `quorum-test-network/docker-compose.yml`
- Smart contract addresses from `.env` file
- Database schema export: `pg_dump --schema-only`

**Metrics to Collect:**

- Blockchain state size after test (check validator1 storage: `docker exec validator1 du -sh /data`)
- PostgreSQL database size: `SELECT pg_size_pretty(pg_database_size('your_db_name'));`
- Number of events emitted vs database audit log rows

---

## 3.4 Experimental Design

### **Experiment 1: Forgery Attack**

**Feasibility:** ‚úÖ Yes

**Recommendations:**

- ‚úÖ Use `uuidv4()` library to generate random UUIDs (Node.js: `npm install uuid`)
- ‚úÖ ADD: Also test with malformed IDs (empty string, SQL injection: `' OR 1=1--`, XSS: `<script>`)
- Verify control endpoint: `GET /api/certificates/:id` (returns 404 if not found)
- Verify blockchain endpoint: `GET /api/blockchain/certificates/verify/:cert_hash` (reverts if cert_exists[hash] == false)

**Needed Info:**

- Sample valid certificate IDs from both systems (1-2 examples)
- Error response format for 404 (JSON structure)
- Whether TypeORM prevents SQL injection (yes, parameterized queries)

**Metrics to Collect:**

- Detection rate: 50/50 = 100% expected
- Response time per forgery attempt (latency distribution)
- HTTP status codes returned (should all be 404 or 400)
- Error messages logged (check for information leakage)

**Practical Implementation:**

```javascript
// Pseudocode
for (let i = 0; i < 50; i++) {
  const fakeId = uuidv4(); // or randomBytes(32).toString('hex') for blockchain
  const response = await fetch(`${API}/certificates/${fakeId}`);
  log({ attempt: i, status: response.status, time: responseTime });
}
```

---

### **Experiment 2: Tampering Attack**

**Feasibility:** ‚ö†Ô∏è Partial - needs clarification

**Recommendations:**

**Centralized (PostgreSQL):**

- ‚úÖ Direct UPDATE is valid tampering simulation
- Run: `UPDATE certificates SET cgpa = cgpa + 0.5 WHERE id = 'target-uuid';`
- Then verify via API: Does tampered value appear? (It will, proving mutability)
- ‚ö†Ô∏è Also tamper with `issuance_date` to test timestamp integrity

**Blockchain (Quorum):**

- ‚ùå CANNOT modify blockchain storage directly (immutable by design)
- ‚úÖ INSTEAD: Test "off-chain tampering" - submit altered data to verify endpoint
  - Step 1: Fetch valid certificate: `GET /api/blockchain/certificates/verify/:hash`
  - Step 2: Modify CGPA in response JSON (increase by 0.5)
  - Step 3: Recompute hash with altered data
  - Step 4: Try to verify altered hash ‚Üí should fail (cert_exists[altered_hash] == false)
- Alternative: Try to issue duplicate certificate with same student_id but higher CGPA (should fail: "Active certificate exists")

**Needed Info:**

- PostgreSQL admin credentials for direct DB access
- Smart contract hash computation function (check `CertificateRegistry.sol` for hash algorithm)
- Whether blockchain has version control (yes: `student_to_latest_version` mapping)

**Metrics to Collect:**

- Centralized: Tamper success rate (should be 100% - proves vulnerability)
- Blockchain: Tamper detection rate (should be 100% - hash mismatch or duplicate prevention)
- Time to detect tampering (immediate for blockchain, never detected for centralized unless audited)
- Audit trail integrity: Can PostgreSQL audit_logs be modified? (Yes)

**Practical Implementation:**

```sql
-- Centralized tampering
UPDATE certificates
SET cgpa = 4.0, issuance_date = NOW()
WHERE student_id = '2021CS001';
```

```javascript
// Blockchain tampering attempt
const validCert = await fetch(
  `/api/blockchain/certificates/verify/${validHash}`
);
const tamperedData = { ...validCert, cgpa: validCert.cgpa + 0.5 };
const tamperedHash = computeHash(tamperedData); // Recompute hash
const response = await fetch(
  `/api/blockchain/certificates/verify/${tamperedHash}`
);
// Expected: 404 or revert error
```

---

### **Experiment 3: Node Failure (Availability Test)**

**Feasibility:** ‚úÖ Yes

**Recommendations:**

- Centralized: Stop PostgreSQL service ‚Üí COMPLETE system failure expected
  - Command: `docker stop <postgres-container>` or `sudo systemctl stop postgresql`
- Blockchain: Stop 1 validator ‚Üí system continues (3/4 validators = quorum maintained)
  - Command: `docker stop quorum-test-network-validator1-1`
- Blockchain: Stop 2 validators ‚Üí system HALTS (2/4 validators < BFT threshold)
  - Commands: `docker stop validator1 validator2`
- ‚úÖ Measure recovery time: Start nodes back up, check when system accepts transactions again

**Needed Info:**

- Docker container names for validators (already found: `validator1-1` through `validator4-1`)
- PostgreSQL connection pooling settings (max connections, timeout)
- IBFT consensus parameters: `epoch` (30000 blocks), `policy` (0 = round-robin)

**Metrics to Collect:**

- System availability: % of time system responds with 200 OK
- Mean Time To Failure (MTTF): Time until first failed request
- Mean Time To Recovery (MTTR): Time to restore service after node restart
- Transaction throughput during degraded mode (2-3 validators)
- Error rate: % of requests returning 500/503

**Practical Implementation:**

```bash
# Test script pseudocode
1. Start issuing certificates every 5 seconds (background job)
2. At t=60s: docker stop validator1
3. Continue requests, log success/failure
4. At t=120s: docker stop validator2
5. Continue requests (should fail now)
6. At t=180s: docker start validator1 validator2
7. Log when first successful request occurs (MTTR)
```

**Statistical Test:**

- Chi-square test for availability difference (uptime% centralized vs blockchain)
- Kaplan-Meier survival curve for failure analysis

---

### **Experiment 4: Replay Attack (JWT Token Reuse)** üÜï

**Feasibility:** ‚úÖ Yes - HIGHLY FEASIBLE

**Recommendations:**

- ‚úÖ Test JWT token security in both systems
- Step 1: Login and obtain JWT token
- Step 2: Perform valid operation (issue certificate)
- Step 3: Logout (or wait for token expiration if implemented)
- Step 4: Attempt to reuse same JWT token
- ‚úÖ This tests authentication layer security (identical in both systems)

**Needed Info:**

- JWT expiration time (check both backends' .env: `JWT_SECRET`, JWT_EXPIRATION config)
- Logout endpoint (if implemented) or manual token invalidation
- Token storage mechanism (localStorage in frontend)

**Metrics to Collect:**

- Replay success rate: % of requests accepted with expired/invalidated token
- Time window vulnerability: How long after logout can token be reused?
- Error responses: 401 Unauthorized vs 403 Forbidden
- Token validation latency: Time to reject invalid token

**Practical Implementation:**

```javascript
// Step 1: Login
const loginResponse = await fetch("/api/auth/login", {
  method: "POST",
  body: JSON.stringify({ username: "admin", password: "password" }),
});
const { access_token } = await loginResponse.json();

// Step 2: Valid operation
const validRequest = await fetch("/api/blockchain/certificates", {
  headers: { Authorization: `Bearer ${access_token}` },
});
console.log("Valid request:", validRequest.status); // 200 OK

// Step 3: Logout or wait for expiration
// await fetch('/api/auth/logout'); // if endpoint exists
// OR: Wait for JWT_EXPIRATION time

// Step 4: Replay attack
const replayRequest = await fetch("/api/blockchain/certificates", {
  headers: { Authorization: `Bearer ${access_token}` },
});
console.log("Replay request:", replayRequest.status); // Should be 401
```

**Why This Matters:**

- Tests session management (critical security control)
- Easy to implement (no infrastructure changes)
- Applicable to BOTH systems equally
- Common real-world attack vector

---

### **Experiment 5: Audit Trail Integrity Test** üÜï

**Feasibility:** ‚úÖ Yes - SHOWS BLOCKCHAIN ADVANTAGE

**Recommendations:**

- ‚úÖ Test whether audit logs can be tampered with
- **Centralized:** Modify audit_logs table directly (simulate malicious admin)
- **Blockchain:** Verify events cannot be altered (immutability proof)

**Centralized Test:**

- Step 1: Issue certificate, log audit entry (action: "ISSUED")
- Step 2: Run SQL: `UPDATE audit_logs SET action = 'REVOKED' WHERE id = X;`
- Step 3: Query audit logs via API
- Step 4: Verify tampered data appears (proves vulnerability)

**Blockchain Test:**

- Step 1: Issue certificate, emit `CertificateIssued` event
- Step 2: Attempt to modify event data (impossible - events are part of block)
- Step 3: Query events via `eth_getLogs` or backend API
- Step 4: Verify original event remains unchanged (proves immutability)

**Needed Info:**

- PostgreSQL audit_logs table schema
- Smart contract event structure: `event CertificateIssued(bytes32 indexed cert_hash, ...)`
- Event querying endpoint: `/api/blockchain/certificates/audit-logs`

**Metrics to Collect:**

- Centralized: Tamper success rate (should be 100%)
- Blockchain: Tamper success rate (should be 0%)
- Detection methods: Can system detect audit tampering? (No for centralized, inherent for blockchain)
- Audit log consistency: Hash of all audit entries before/after tampering

**Practical Implementation:**

```sql
-- Centralized tampering
UPDATE audit_logs
SET action = 'REVOKED', details = '{"fake": "data"}'
WHERE certificate_id = 'target-uuid';

-- Verify via API
GET /api/certificates/audit-logs?certificate_id=target-uuid
-- Will return tampered data
```

```javascript
// Blockchain immutability verification
const eventsBefore = await contract.queryFilter(
  contract.filters.CertificateIssued(certHash)
);

// Attempt to modify event (this will fail - no such operation exists)
// Events are part of transaction receipt, cannot be altered

const eventsAfter = await contract.queryFilter(
  contract.filters.CertificateIssued(certHash)
);

// Verify events are identical
assert.deepEqual(eventsBefore, eventsAfter);
```

**Why This Matters:**

- Directly demonstrates blockchain's core value proposition (immutability)
- Shows centralized vulnerability (admin can rewrite history)
- Easy to execute (no complex setup)
- Highly relevant to certificate verification systems (audit trail is critical)

---

### **Experiment 6: Concurrent Transaction Test (Scalability)** üÜï

**Feasibility:** ‚úÖ Yes - PERFORMANCE COMPARISON

**Recommendations:**

- ‚úÖ Test how both systems handle simultaneous certificate issuance
- Simulate 10, 25, 50 concurrent users issuing certificates
- Measure throughput (transactions/second) and latency degradation

**Needed Info:**

- Database connection pool size (PostgreSQL max_connections)
- Blockchain gas limit per block (check genesis.json: `"gasLimit": "0xf7b760"`)
- Backend concurrency limits (NestJS event loop can handle ~1000 concurrent requests)

**Metrics to Collect:**

- Throughput: Certificates issued per second at each concurrency level
- Latency: Response time distribution (p50, p95, p99) under load
- Error rate: % of requests that fail (500 errors, timeouts)
- Resource utilization: CPU%, RAM%, Disk I/O during peak load
- Transaction queue depth: Blockchain mempool size vs database connection queue

**Practical Implementation:**

```javascript
// Using Promise.all for concurrent requests
async function concurrentTest(numConcurrent) {
  const startTime = Date.now();
  const promises = [];

  for (let i = 0; i < numConcurrent; i++) {
    promises.push(
      fetch("/api/blockchain/certificates", {
        method: "POST",
        headers: { Authorization: `Bearer ${token}` },
        body: JSON.stringify({
          student_id: `2021CS${i.toString().padStart(3, "0")}`,
          student_name: `Student ${i}`,
          degree: "Bachelor of Science",
          program: "Computer Science",
          cgpa: 3.5,
          issuing_authority: "Test University",
        }),
      })
    );
  }

  const results = await Promise.allSettled(promises);
  const endTime = Date.now();

  const successful = results.filter((r) => r.status === "fulfilled").length;
  const failed = results.filter((r) => r.status === "rejected").length;
  const throughput = successful / ((endTime - startTime) / 1000);

  return { successful, failed, throughput, duration: endTime - startTime };
}

// Test at different concurrency levels
for (const level of [10, 25, 50]) {
  const result = await concurrentTest(level);
  console.log(`Concurrency ${level}:`, result);
}
```

**Expected Results:**

- **Centralized:** High throughput (100-200 TPS), low latency until connection pool exhausted
- **Blockchain:** Lower throughput (20-50 TPS), higher latency due to block time (~5s), but consistent

**Why This Matters:**

- Tests real-world scenario (university issuing many certificates simultaneously)
- Reveals performance bottlenecks (DB connections vs consensus)
- Shows scalability trade-offs (speed vs immutability)
- Easy to implement with existing endpoints

**Statistical Test:**

- Two-way ANOVA: System (centralized/blockchain) √ó Concurrency Level (10/25/50) ‚Üí Latency
- Linear regression: Throughput vs Concurrency Level (identify saturation point)

---

### **Experiment 7: Data Consistency Test (Certificate Versioning)** üÜï OPTIONAL

**Feasibility:** ‚úÖ Yes - TESTS BLOCKCHAIN UNIQUE FEATURE

**Recommendations:**

- ‚úÖ Test blockchain's versioning system vs centralized approach
- Issue certificate v1 for student ‚Üí Revoke ‚Üí Issue v2 with updated data
- Verify blockchain maintains version history, centralized overwrites or soft-deletes

**Needed Info:**

- Blockchain versioning mappings: `student_to_latest_version`, `student_version_to_hash`
- Centralized approach: Soft delete (is_revoked flag) or hard delete?
- API endpoints: `GET /api/blockchain/certificates/student/:id/versions`

**Metrics to Collect:**

- Version retrieval time: How long to fetch all versions?
- Version completeness: Can you retrieve revoked certificates?
- Storage overhead: Space used for version history (blockchain state size vs DB row count)

**Practical Implementation:**

```javascript
// Issue v1
const v1 = await issueCertificate({ student_id: "2021CS001", cgpa: 3.5 });

// Revoke v1
await revokeCertificate(v1.cert_hash);

// Issue v2
const v2 = await issueCertificate({ student_id: "2021CS001", cgpa: 3.8 });

// Retrieve all versions
const versions = await fetch(
  "/api/blockchain/certificates/student/2021CS001/versions"
);
// Blockchain: Returns [v1, v2] with full history
// Centralized: Returns only v2? Or both with is_revoked flag?
```

**Why This Matters:**

- Demonstrates blockchain's version control (unique advantage)
- Tests data retention requirements (audit trail completeness)
- Optional because versioning may not be critical for all use cases

---

## 3.5 Data Collection

**Feasibility:** ‚úÖ Yes

**Recommendations:**

- ‚úÖ Node.js with `fetch()` is appropriate
- Use `performance.now()` for high-resolution timing (microsecond precision)
- ADD: System resource monitoring with `node-os-utils` or `systeminformation` library
- Log to JSON Lines (.jsonl) format instead of CSV (easier to parse nested data)
- Use `pino` logger for structured logging (faster than console.log)

**Needed Info:**

- JWT token management (store in environment variable or config file)
- API rate limits (if any - prevent accidental DDoS)
- Concurrent request handling (use Promise.all for parallel tests, async/await for sequential)

**Metrics to Collect:**

- Per-request: timestamp, endpoint, status_code, response_time_ms, request_size_bytes, response_size_bytes
- Per-system: cpu_percent, memory_mb, disk_io_reads, disk_io_writes, network_bytes_sent, network_bytes_received
- Per-experiment: total_requests, successful_requests, failed_requests, avg_latency, p50, p95, p99

**Practical Implementation:**

```javascript
// Install dependencies
npm install node-fetch pino uuid systeminformation

// Logging structure
const logger = pino({ destination: 'experiment1.jsonl' });

async function testForgery() {
  const start = performance.now();
  const response = await fetch(url, { headers: { Authorization: `Bearer ${token}` } });
  const end = performance.now();

  logger.info({
    experiment: 'forgery',
    attempt: i,
    status: response.status,
    latency_ms: end - start,
    timestamp: new Date().toISOString()
  });
}
```

---

## 3.6 Statistical Analysis

**Feasibility:** ‚úÖ Yes with corrections

**Recommendations:**

- ‚úÖ Shapiro-Wilk for normality testing (latency data)
- ‚úÖ Independent samples t-test (if normal) OR Mann-Whitney U test (if non-normal) for latency comparison
- ‚úÖ Chi-square test for detection rates (categorical: success/failure)
- ‚ö†Ô∏è ADD: **Effect size calculations**:
  - Cohen's d for latency differences (standardized mean difference)
  - Odds ratio for detection rate differences
- ‚ö†Ô∏è ADD: **Confidence intervals** (95% CI) for all metrics
- ‚ö†Ô∏è Multiple comparisons issue: Use Bonferroni correction if testing >3 hypotheses (Œ± = 0.05/n)

**Needed Info:**

- Sample size calculation: Need ~30 observations per condition for t-test validity (you have 50, good)
- Software: R, Python (scipy, statsmodels), or SPSS
- Assumption checking: Homogeneity of variance (Levene's test before t-test)

**Metrics to Collect:**

- Descriptive stats: mean, median, SD, IQR, min, max for latency
- Inferential stats: test statistic, p-value, effect size, CI
- Assumption violations: skewness, kurtosis, outliers (box plots)

**Practical Implementation:**

```python
# Python example
from scipy import stats
import numpy as np

# Latency comparison
centralized_latency = np.array([...])  # 50 measurements
blockchain_latency = np.array([...])   # 50 measurements

# Test normality
_, p_shapiro = stats.shapiro(centralized_latency)
if p_shapiro > 0.05:
    # Normal: use t-test
    t_stat, p_value = stats.ttest_ind(centralized_latency, blockchain_latency)
else:
    # Non-normal: use Mann-Whitney
    u_stat, p_value = stats.mannwhitneyu(centralized_latency, blockchain_latency)

# Effect size (Cohen's d)
pooled_std = np.sqrt((np.var(centralized_latency) + np.var(blockchain_latency)) / 2)
cohen_d = (np.mean(blockchain_latency) - np.mean(centralized_latency)) / pooled_std

# Detection rate comparison (chi-square)
contingency_table = [[central_detections, central_misses],
                     [blockchain_detections, blockchain_misses]]
chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)
```

---

## 3.7 Environment

**Feasibility:** ‚úÖ Yes - sufficient

**Recommendations:**

- ‚úÖ 8-core, 32GB RAM is MORE than enough (Quorum validators typically use 1-2GB each)
- ‚ö†Ô∏è Network latency simulation: Docker network is localhost (0ms latency) - NOT realistic
  - ADD: Use `tc` (traffic control) to simulate WAN latency: `sudo tc qdisc add dev eth0 root netem delay 50ms`
  - Or: Run validators in separate VMs/containers with network bridges
- ‚úÖ SSD is good for disk I/O performance
- Document exact versions: Node.js, PostgreSQL, Quorum/GoQuorum, Solidity compiler

**Needed Info:**

- Docker network configuration: Check `quorum-test-network/docker-compose.yml` for network mode (bridge vs host)
- Validator resource allocation: CPU/memory limits per container
- PostgreSQL tuning parameters: `shared_buffers`, `work_mem`, `max_connections`

**Metrics to Collect:**

- System specs in methodology: CPU model, RAM speed, disk type (NVMe/SATA)
- Docker stats during tests: `docker stats --no-stream`
- Network latency between validators: `docker exec validator1 ping validator2`

**Practical Implementation:**

```bash
# Check Docker network
docker network inspect quorum-test-network_quorum-dev-quickstart

# Monitor resources during experiments
docker stats --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}" > resources.log &

# Simulate 50ms network latency (optional)
sudo tc qdisc add dev docker0 root netem delay 50ms 10ms distribution normal
```

---

## 3.8 Limitations

**Feasibility:** ‚úÖ Yes - honest limitations

**Recommendations:**

- ‚úÖ Small network (4 nodes) is acceptable - mention this reflects "small consortium" scenario
- ‚úÖ No advanced attacks (side-channel, cryptographic) is acceptable for master's thesis
- ‚úÖ Assumes secure keys is valid - key management is separate research area
- ‚ö†Ô∏è ADD: **Scalability limitation** - not testing with 100K+ certificates (mention as future work)
- ‚ö†Ô∏è ADD: **Consensus algorithm limitation** - only tested IBFT, not PoW or other algorithms
- ‚ö†Ô∏è ADD: **Network assumption** - Docker localhost, not geo-distributed nodes
- ‚ö†Ô∏è ADD: **Threat model scope** - no testing of frontend vulnerabilities (XSS, CSRF)

**Needed Info:**

- What production deployments typically use (research similar blockchain systems)
- Academic standards for experimental validity (consult advisor)

**Metrics to Collect:**

- N/A for limitations section (descriptive only)

**Practical Implementation:**

- Create "Limitations" subsection in methodology chapter
- Cross-reference with "Future Work" section in conclusion

---

## 3.9 Ethics

**Feasibility:** ‚úÖ Yes - ethically sound

**Recommendations:**

- ‚úÖ Synthetic data only is acceptable
- ‚úÖ Isolated environment is appropriate
- ‚ùå NO IRB approval needed (no human subjects, no real PII)
- ‚ö†Ô∏è ADD: Statement about data retention (will you delete test data after thesis?)
- ‚ö†Ô∏è ADD: Mention open-source components and licensing (MIT, Apache, etc.)

**Needed Info:**

- University's ethics policy for synthetic data research
- Whether code will be published (GitHub) - if yes, redact private keys from commits

**Metrics to Collect:**

- N/A for ethics section (documentation only)

**Practical Implementation:**

- Add ethics statement to thesis: "This research uses synthetic data only. No personal identifiable information (PII) or real student records are used. All experiments are conducted in an isolated Docker environment with no external network access."
- Check `.gitignore` to ensure `.env` files are not committed

---

## 3.10 Summary & Overall Assessment

**Feasibility:** ‚úÖ Yes - methodology is complete and implementable

**Biggest Risk:** ‚ö†Ô∏è **Blockchain tampering test is UNCLEAR** - you cannot modify immutable blockchain data directly. Revise to test "verification of tampered data" (off-chain modification) instead of "on-chain tampering."

**Recommendations:**

**Strengths of Your Methodology:**

1. ‚úÖ Clear comparative design (control vs treatment)
2. ‚úÖ Multiple threat scenarios (forgery, tampering, availability, replay, audit integrity) üÜï
3. ‚úÖ Quantitative metrics (latency, detection rate, uptime, throughput) üÜï
4. ‚úÖ Appropriate statistical tests
5. ‚úÖ Realistic implementation constraints acknowledged
6. ‚úÖ Tests blockchain unique features (immutability, versioning) üÜï
7. ‚úÖ Performance AND security comparison (comprehensive) üÜï

**Critical Additions Needed:**

1. ‚ö†Ô∏è **Pre-experiment baseline testing** (establish normal operation metrics)
2. ‚ö†Ô∏è **Input validation tests** (malformed data, SQL injection attempts)
3. ‚úÖ **Replay attack test** (JWT token reuse) - NOW ADDED
4. ‚úÖ **Audit trail integrity test** (tamper detection) - NOW ADDED
5. ‚úÖ **Concurrent transaction test** (scalability) - NOW ADDED
6. ‚ö†Ô∏è **Effect size calculations** (Cohen's d, odds ratios)
7. ‚ö†Ô∏è **Clarify blockchain tampering** (test verification, not modification)

**Recommended Test Sequence:**

1. **Phase 0:** Baseline performance (100 normal operations on each system)
2. **Phase 1:** Forgery attacks (50 fake IDs + 10 malformed inputs)
3. **Phase 2:** Tampering simulation (centralized: direct UPDATE; blockchain: altered data verification)
4. **Phase 3:** Availability tests (stop 1 node, 2 nodes, measure recovery)
5. **Phase 4:** Replay attacks (reuse JWT tokens after logout) üÜï
6. **Phase 5:** Audit trail integrity (tamper with centralized logs, verify blockchain immutability) üÜï
7. **Phase 6:** Concurrent transaction test (10/25/50 simultaneous users) üÜï
8. **Phase 7 (OPTIONAL):** Version history test (blockchain versioning vs centralized) üÜï
9. **Phase 8:** Statistical analysis and comparison

**Timeline Estimate:**

- Test script development: 1.5-2 weeks (4 new experiments)
- Experiment execution: 3-4 days (with retries and reproducibility checks)
- Data analysis: 4-5 days (more data points from additional experiments)
- Total: ~3 weeks for complete experimental phase

**Success Criteria:**

- All experiments execute without errors
- Detection rates calculable for both systems
- Statistically significant differences found (or justified null results)
- Reproducible results (repeat each experiment 3 times)
- Clear demonstration of blockchain advantages (immutability, versioning) AND trade-offs (latency, throughput)

---

## Summary of NEW Experiments Added üÜï

### **Why These 4 Experiments Make Your Thesis Exceptional:**

**Experiment 4: Replay Attack (JWT Token Reuse)**

- ‚úÖ Tests authentication security (often overlooked in blockchain comparisons)
- ‚úÖ Easy to implement (no infrastructure changes)
- ‚úÖ Applicable to BOTH systems equally
- ‚úÖ Shows blockchain doesn't solve ALL security issues (JWT layer is identical)

**Experiment 5: Audit Trail Integrity Test**

- ‚úÖ DIRECTLY demonstrates blockchain's core value (immutability)
- ‚úÖ Shows centralized vulnerability (admin can rewrite history)
- ‚úÖ Easy to execute (SQL UPDATE vs blockchain verification)
- ‚úÖ Highly relevant to certificate systems (audit integrity is CRITICAL)

**Experiment 6: Concurrent Transaction Test**

- ‚úÖ Tests real-world scalability (simultaneous certificate issuance)
- ‚úÖ Reveals performance bottlenecks (DB connections vs consensus)
- ‚úÖ Quantitative comparison (throughput, latency under load)
- ‚úÖ Shows blockchain trade-off (lower TPS but predictable performance)

**Experiment 7: Version History Test (OPTIONAL)**

- ‚úÖ Tests blockchain unique feature (native versioning)
- ‚úÖ Shows data retention advantage
- ‚úÖ Optional if time-constrained (Exp 4-6 are more critical)

### **Impact on Thesis Quality:**

**Original (3 experiments):**

- Covers basics: forgery, tampering, availability
- Good foundation but limited depth

**Enhanced (7 experiments):**

- Covers security (forgery, tampering, replay, audit integrity)
- Covers availability (node failure)
- Covers performance (concurrent transactions)
- Covers unique features (versioning)
- Demonstrates blockchain advantages AND limitations
- More comprehensive, defensible conclusions

**Estimated Additional Time:**

- +1 week for scripting (Exp 4-6 are straightforward)
- +1-2 days for execution
- +1-2 days for analysis
- **Total: +10 days investment for significantly stronger thesis**

---

## Final Recommendations

### **Must-Do Before Experimentation:**

1. ‚úÖ Complete control system API endpoints (you said "few days")
2. ‚úÖ Verify both systems return equivalent data structures
3. ‚úÖ Create seed data script (100 valid certificates per system)
4. ‚úÖ Document baseline performance metrics
5. ‚úÖ Write test scripts for each experiment (reusable, parameterized)

### **Must-Have in Methodology Chapter:**

1. System architecture diagram (centralized vs blockchain)
2. Threat model table (attack type, target, expected outcome)
3. Experimental procedure flowchart (step-by-step for each test)
4. Data collection schema (what columns in CSV/JSON logs)
5. Statistical analysis plan (which test for which hypothesis)

### **Red Flags to Avoid:**

- ‚ùå Claiming blockchain is "unhackable" (no system is)
- ‚ùå Testing centralized system without JWT auth (security should be comparable)
- ‚ùå Ignoring failed experiments (document and explain anomalies)
- ‚ùå P-hacking (don't keep running tests until you get p<0.05)
- ‚ùå Overgeneralizing results (e.g., "all blockchains are slower" based on IBFT only)

### **Contact Points for Further Help:**

- Test script implementation: Another AI or developer with your detailed plan
- Statistical analysis: R/Python with your collected CSV/JSON data
- Visualization: Matplotlib, ggplot2, or Tableau for graphs/charts
- Thesis writing: Follow your methodology feedback to write detailed methods section

---

**This methodology is THESIS-READY with the recommended additions. Good luck with implementation!**
